{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-BeZ0mhTEZT"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Практическое задание 5. Решающие деревья\n",
        "\n",
        "### Общая информация\n",
        "Дата выдачи: 18.11.2022\n",
        "\n",
        "Мягий дедлайн: 23:59MSK 30.11.2022\n",
        "\n",
        "Жестокий дедлайн: 23:59MSK 06.12.2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l790O-S-TEZU"
      },
      "source": [
        "### О задании\n",
        "\n",
        "Задание состоит из двух разделов:\n",
        "1. В первом разделе вы научитесь применять деревья из sklearn для задачи классификации. Вы посмотрите какие разделяющие поверхности деревья строят для различных датасетов и проанализируете их зависимость от различных гиперпараметров.\n",
        "2. Во втором разделе вы попробуете реализовать свое решающее дерево и сравните его со стандартное имплиментацией из sklearn. Вы также протестируете деревья на более сложных датасетах и сравните различные подходы к кодированию категориальных признаков.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "\n",
        "### Формат сдачи\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "* Ноутбук homework-practice-05-trees-Username.ipynb\n",
        "* Модуль hw5code.py\n",
        "* Ссылки на посылки в Яндекс.Контесте для обеих задач\n",
        "\n",
        "В контест https://contest.yandex.ru/contest/43413/problems/ нужно отправить файл hw5code.py с реализованными функциями и классами.\n",
        "\n",
        "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
        "\n",
        "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже:\n",
        "\n",
        "__Оценка:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjUoF1GZTEZW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from matplotlib.colors import Colormap, ListedColormap\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXPLGqNCTEZY"
      },
      "source": [
        "# 1. Решающие деревья. Визуализация."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUjqXVx6TEZY"
      },
      "source": [
        "В этой части мы рассмотрим два простых двумерных датасета сделанных с помощью `make_moons`, `make_circles` и посмотрим как ведет себя разделяющая поверхность в зависимости от различных гиперпараметров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZTll755TEZZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "datasets = [\n",
        "    make_circles(noise=0.2, factor=0.5, random_state=42),\n",
        "    make_moons(noise=0.2, random_state=42),\n",
        "    make_classification(n_classes=3, n_clusters_per_class=1, n_features=2, class_sep=.8, random_state=3,\n",
        "                        n_redundant=0., )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RazQQTYvTEZZ"
      },
      "outputs": [],
      "source": [
        "palette = sns.color_palette(n_colors=3)\n",
        "cmap = ListedColormap(palette)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I8-BM9fTEZa"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "for i, (x, y) in enumerate(datasets):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap, alpha=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-IG5UiBTEZa"
      },
      "source": [
        "__Задание 1. (1 балл)__\n",
        "\n",
        "Для каждого датасета обучите решающее дерево с параметрами по умолчанию, предварительно разбив выборку на обучающую и тестовую. Постройте разделящие поверхности (для этого воспользуйтесь функцией `plot_surface`, пример ниже). Посчитайте accuracy на обучающей и тестовой выборках. Сильно ли деревья переобучились?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBttFqh-TEZb"
      },
      "outputs": [],
      "source": [
        "def plot_surface(clf, X, y):\n",
        "    plot_step = 0.01\n",
        "    palette = sns.color_palette(n_colors=len(np.unique(y)))\n",
        "    cmap = ListedColormap(palette)\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
        "\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)\n",
        "\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, alpha=.7,\n",
        "                edgecolors=np.array(palette)[y], linewidths=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcfPPap5TEZb"
      },
      "outputs": [],
      "source": [
        "# Пример:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X, y = datasets[2]\n",
        "lr  = LinearRegression().fit(X, y)\n",
        "plot_surface(lr, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujG9UUxTTEZc"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UDg3DZKTEZc"
      },
      "source": [
        "__Ответ:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LddFdX_VTEZc"
      },
      "source": [
        "__Задание 2. (1.5 балла)__\n",
        "\n",
        "Попробуйте перебрать несколько параметров для регуляризации (напр. `max_depth`, `min_samples_leaf`). Для каждого набора гиперпараметров постройте разделяющую поверхность, выведите обучающую и тестовую ошибки. Можно делать кросс-валидацию или просто разбиение на трейн и тест, главное делайте каждый раз одинаковое разбиение, чтобы можно было корректно сравнивать (помните же, что итоговое дерево сильно зависит от небольшого изменения обучающей выборки?). Проследите как меняется разделяющая поверхность и обобщающая способность. Почему так происходит, одинаково ли изменение для разных датасетов?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKJZfzVDTEZd"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQGcNWj-TEZd"
      },
      "source": [
        "__Ответ:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gALYvCrTEZd"
      },
      "source": [
        "# 2. Решающие деревья своими руками"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8juQjFKTEZd"
      },
      "source": [
        "В этой части вам нужно реализовать свой класс для обучения решающего дерева в задаче бинарной классификации с возможностью обработки вещественных и категориальных признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eEp7M9ATEZe"
      },
      "source": [
        "__Задание 3. (1.5 балл)__\n",
        "\n",
        "Реализуйте функцию find_best_split из модуля hw5code.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJrV4F3JTEZe"
      },
      "source": [
        "__Задание 4. (0.5 балла)__\n",
        "\n",
        "Загрузите таблицу [students.csv](https://github.com/esokolov/ml-course-hse/blob/master/2022-fall/homeworks-practice/homework-practice-05-trees/students.csv) (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте scatter-графики \"значение признака — класс\" для всех пяти признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7w-m-u9TEZe"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUQ4vjR0TEZf"
      },
      "source": [
        "__Задание 5. (0.5 балла)__\n",
        "\n",
        "Исходя из кривых значений критерия Джини, по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой scatter-графиков? Как бы охарактеризовали вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFg9VPmuTEZf"
      },
      "source": [
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_0CMUJyTEZf"
      },
      "source": [
        "__Задание 6. (1.5 балла).__\n",
        "\n",
        "Разберитесь с уже написанным кодом в классе DecisionTree модуля hw5code.py. Найдите ошибки в реализации метода \\_fit_node. Напишите функцию \\_predict_node.\n",
        "\n",
        " Построение дерева осуществляется согласно базовому жадному алгоритму, предложенному в [лекции](https://github.com/esokolov/ml-course-hse/blob/master/2020-fall/lecture-notes/lecture07-trees.pdf) в разделе «Построение дерева». Выбор лучшего разбиения необходимо производить по критерию Джини. Критерий останова: все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку. Ответ в листе: наиболее часто встречающийся класс в листе. Для категориальных признаков выполняется преобразование, описанное в лекции в разделе «Учет категориальных признаков»."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCAEfUz2TEZf"
      },
      "source": [
        "__Задание 7. (0.5 балла)__\n",
        "\n",
        "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец — это целевая переменная (e — edible, p — poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy.\n",
        "\n",
        "У вас должно получиться значение accuracy, равное единице (или очень близкое к единице), и не очень глубокое дерево."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOzzO5SfTEZg"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RClb2IAyTEZg"
      },
      "source": [
        "__Задание 8. (бонус, 1 балл)__\n",
        "\n",
        "Реализуйте в классе DecisionTree поддержку параметров max_depth, min_samples_split и min_samples_leaf по аналогии с DecisionTreeClassifier. Постройте графики зависимости качества предсказания в зависимости от этих параметров для набора данных tic-tac-toe (см. следующий пункт)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35i9HYPDTEZg"
      },
      "source": [
        "__Задание 9. (2 балла)__\n",
        "\n",
        "Загрузите следующие наборы данных (напомним, что pandas умеет загружать файлы по url, в нашем случае это файл \\*.data), предварительно ознакомившись с описанием признаков и целевой переменной в каждом из них (она записаны в Data Folder, в файле *.names): \n",
        "* [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom) (загрузили в предыдущем пункте, классы записаны в нулевом столбце),\n",
        "* [tic-tac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце)\n",
        "* [cars](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) (классы записаны в последнем столбце, считаем что unacc, acc — это класс 0, good, vgood — класс 1)\n",
        "* [nursery](https://archive.ics.uci.edu/ml/datasets/Nursery) (классы записаны в последнем столбце, считаем, что not_recom и recommend — класс 0, very_recom, priority, spec_prior — класс 1).\n",
        "\n",
        "Закодируйте категориальные признаки, использовав LabelEncoder. С помощью cross_val_score (cv=10) оцените accuracy на каждом из этих наборов данных следующих алгоритмов:\n",
        "* DecisionTree, считающий все признаки вещественными\n",
        "* DecisionTree, считающий все признаки категориальными\n",
        "* DecisionTree, считающий все признаки вещественными + one-hot-encoding всех признаков\n",
        "* DecisionTreeClassifier из sklearn. Запишите результат в pd.DataFrame (по строкам — наборы данных, по столбцам — алгоритмы).\n",
        "\n",
        "Рекомендации:\n",
        "* Чтобы cross_val_score вычисляла точность, нужно передать scoring=make_scorer(accuracy_score), обе фукнции из sklearn.metrics.\n",
        "* Если вам позволяет память (а она скорее всего позволяет), указывайте параметр sparse=False в OneHotEncoder (если вы, конечно, используете его). Иначе вам придется добиваться того, чтобы ваша реализация дерева умела работать с разреженными матрицами (что тоже, в целом, не очень сложно)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzHWYQYlTEZg"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyHrtXW0TEZh"
      },
      "source": [
        "__Задание 10. (1 балла)__\n",
        "\n",
        "Проанализируйте результаты эксперимента. \n",
        "Одинаково ли для разных наборов данных ранжируются алгоритмы? \n",
        "Порассуждайте, почему так происходит. \n",
        "\n",
        "Обратите внимание на значение признаков в разных наборах данных. \n",
        "Присутствует ли в результатах какая-то компонента случайности? \n",
        "Можно ли повлиять на нее и улушить работу алгоритмов?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H9e_xANTEZh"
      },
      "source": [
        "**Ответ:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsGY78W5TEZh"
      },
      "source": [
        "Вставьте что угодно, описывающее ваши впечатления от этого задания:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G__5d2pkTEZh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}